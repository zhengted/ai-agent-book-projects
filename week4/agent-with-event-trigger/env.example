# LLM Provider Configuration (matching conversational_agent.py)
# Choose one provider and set the corresponding API key

# Provider selection (default: kimi)
# Options: siliconflow, doubao, kimi, moonshot, openrouter
LLM_PROVIDER=kimi

# API Keys (set the one matching your provider)
KIMI_API_KEY=your-kimi-api-key-here
# SILICONFLOW_API_KEY=your-siliconflow-api-key-here
# DOUBAO_API_KEY=your-doubao-api-key-here
# OPENROUTER_API_KEY=your-openrouter-api-key-here

# Optional: Override default model for your provider
# LLM_MODEL=kimi-k2-0905-preview

# Default models per provider:
# - siliconflow: Qwen/Qwen3-235B-A22B-Thinking-2507
# - doubao: doubao-seed-1-6-thinking-250715
# - kimi/moonshot: kimi-k2-0905-preview
# - openrouter: google/gemini-2.5-pro
#   (also supports: openai/gpt-5, anthropic/claude-sonnet-4)

# Optional: Custom server port (default: 4242)
# AGENT_PORT=4242